vw_opts only included if there is a change

1st bag of words baseline:
features:
tokens that are
    1) >= 3 chars
    2) all converted to lowercase

vw_opts = {
    # General options
    "random_seed": 1,
    # Input options
    # Output options
    "progress": 1000,
    # Example Manipulation options
    # Update rule options
    # Weight options
    # Holdout options
    # Feature namespace options
    # Multiclass options
    "oaa": 20
    # Other options
}

accuracy score = 0.8840025493945188


2nd bag of words baseline:
features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) token.lower used as features
    pure_text section:
        1) same as Subject section

vw_opts = {
    # General options
    "random_seed": 1,
    # Input options
    # Output options
    "progress": 1000,
    # Example Manipulation options
    # Update rule options
    "loss_function": "logistic",
    # Weight options
    "bit_precision": 28,
    # Holdout options
    # Feature namespace options
    # Multiclass options
    "oaa": 20
    # Other options
}

Classification report:
              precision    recall  f1-score   support

           1       0.91      0.87      0.89       209
           2       0.85      0.84      0.85       253
           3       0.82      0.85      0.83       250
           4       0.85      0.82      0.83       238
           5       0.87      0.90      0.88       233
           6       0.91      0.91      0.91       237
           7       0.81      0.89      0.85       245
           8       0.93      0.95      0.94       241
           9       0.95      0.95      0.95       244
          10       0.98      0.98      0.98       247
          11       1.00      0.98      0.99       246
          12       0.96      0.91      0.93       240
          13       0.88      0.88      0.88       223
          14       0.94      0.93      0.93       248
          15       0.93      0.97      0.95       258
          16       0.89      0.94      0.91       250
          17       0.94      0.92      0.93       224
          18       0.98      0.95      0.96       255
          19       0.93      0.87      0.90       200
          20       0.81      0.81      0.81       166

    accuracy                           0.91      4707
   macro avg       0.91      0.91      0.91      4707
weighted avg       0.91      0.91      0.91      4707

Accuracy score:
0.9075844486934354

1st word vectors baseline:

features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) token.lower used to find token.vector. Token.vector used as feature

    pure_text section:
        1) same as Subject section

Classification report:
              precision    recall  f1-score   support

           1       0.84      0.77      0.81       209
           2       0.76      0.81      0.78       253
           3       0.75      0.83      0.79       250
           4       0.71      0.74      0.73       238
           5       0.87      0.86      0.87       233
           6       0.88      0.85      0.86       237
           7       0.80      0.78      0.79       245
           8       0.86      0.88      0.87       241
           9       0.91      0.91      0.91       244
          10       0.96      0.94      0.95       247
          11       0.96      0.96      0.96       246
          12       0.96      0.87      0.91       240
          13       0.82      0.80      0.81       223
          14       0.94      0.87      0.90       248
          15       0.90      0.90      0.90       258
          16       0.84      0.88      0.86       250
          17       0.91      0.88      0.90       224
          18       0.93      0.89      0.91       255
          19       0.79      0.88      0.83       200
          20       0.70      0.76      0.73       166

    accuracy                           0.86      4707
   macro avg       0.85      0.85      0.85      4707
weighted avg       0.86      0.86      0.86      4707

Accuracy score:
0.8551094115147653

2nd word vectors baseline:

features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) tokens converted to token.lower
        4) doc.vector found and used as feature

    pure_text section:
        1) same as Subject section

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.241272
total feature number = 648354653

average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.743000 0.743000         1000         1000.0       10       10      606
0.651000 0.559000         2000         2000.0       18       18      609
0.589333 0.466000         3000         3000.0       11        4      606
0.550750 0.435000         4000         4000.0       12       12      606
0.516000 0.377000         5000         5000.0       10        7      607
0.491667 0.370000         6000         6000.0        1        1      608
0.470000 0.340000         7000         7000.0        2        2      607
0.451125 0.319000         8000         8000.0       12       12      606
0.436333 0.318000         9000         9000.0       14       14      607
0.423800 0.311000        10000        10000.0        9        9      608
0.411182 0.285000        11000        11000.0       13        7      607
0.399167 0.267000        12000        12000.0        6        6      607
0.391385 0.298000        13000        13000.0        7       20      607
0.381214 0.249000        14000        14000.0       10       10      606
0.380072 0.247934        15000        15000.0  unknown        6      609
0.380072     n.a.        16000        16000.0  unknown       11      609
0.380072     n.a.        17000        17000.0  unknown        7      607
0.380072     n.a.        18000        18000.0  unknown        5      608
Classification report:
              precision    recall  f1-score   support

           1       0.97      0.86      0.91       209
           2       0.79      0.53      0.64       253
           3       0.81      0.64      0.72       250
           4       0.55      0.57      0.56       238
           5       0.56      0.67      0.61       233
           6       0.58      0.57      0.57       237
           7       0.25      0.73      0.37       245
           8       0.90      0.74      0.82       241
           9       0.90      0.84      0.87       244
          10       0.91      0.73      0.81       247
          11       0.81      0.82      0.81       246
          12       0.98      0.81      0.89       240
          13       0.84      0.74      0.78       223
          14       0.91      0.81      0.86       248
          15       0.97      0.83      0.90       258
          16       0.94      0.82      0.87       250
          17       0.98      0.82      0.89       224
          18       0.98      0.91      0.95       255
          19       0.98      0.81      0.89       200
          20       0.87      0.83      0.85       166

    accuracy                           0.75      4707
   macro avg       0.82      0.75      0.78      4707
weighted avg       0.82      0.75      0.78      4707

Accuracy score:
0.7516464839600595

3rd word vectors baseline:

features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) tokens converted to token.lower and used as features

    pure_text section:
        1) same as Subject section (1,2,3)
        2) doc.vector used as feature instead of token.lower

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.380072
total feature number = 11436653

Classification report:
              precision    recall  f1-score   support

           1       0.89      0.79      0.84       209
           2       0.68      0.41      0.51       253
           3       0.76      0.66      0.71       250
           4       0.59      0.61      0.60       238
           5       0.69      0.67      0.68       233
           6       0.68      0.62      0.65       237
           7       0.56      0.73      0.64       245
           8       0.70      0.73      0.72       241
           9       0.70      0.81      0.75       244
          10       0.60      0.82      0.70       247
          11       0.68      0.87      0.76       246
          12       0.68      0.84      0.75       240
          13       0.69      0.65      0.67       223
          14       0.76      0.68      0.72       248
          15       0.83      0.83      0.83       258
          16       0.67      0.79      0.73       250
          17       0.80      0.79      0.80       224
          18       0.92      0.85      0.88       255
          19       0.91      0.61      0.73       200
          20       0.79      0.43      0.56       166

    accuracy                           0.71      4707
   macro avg       0.73      0.71      0.71      4707
weighted avg       0.73      0.71      0.71      4707

Accuracy score:
0.7148927129806671

4th word vectors baseline:

features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) tokens converted to token.lower
        4) doc.vector used as feature

    pure_text section:
        1) same as Subject section (1,2,3), token.lemma_ used as feature

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.374549
total feature number = 5850357

Classification report:
              precision    recall  f1-score   support

           1       0.95      0.91      0.93       209
           2       0.89      0.83      0.86       253
           3       0.85      0.88      0.86       250
           4       0.82      0.78      0.80       238
           5       0.76      0.90      0.82       233
           6       0.90      0.91      0.91       237
           7       0.75      0.90      0.82       245
           8       0.93      0.91      0.92       241
           9       0.97      0.93      0.95       244
          10       0.95      0.95      0.95       247
          11       0.99      0.97      0.98       246
          12       0.97      0.92      0.94       240
          13       0.93      0.90      0.91       223
          14       0.96      0.93      0.95       248
          15       0.99      0.94      0.96       258
          16       0.90      0.95      0.93       250
          17       0.98      0.92      0.95       224
          18       0.99      0.96      0.98       255
          19       0.95      0.95      0.95       200
          20       0.83      0.86      0.84       166

    accuracy                           0.91      4707
   macro avg       0.91      0.91      0.91      4707
weighted avg       0.91      0.91      0.91      4707

Accuracy score:
0.910558742298704

5th word vectors baseline:

features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) tokens converted to token.lower
        4) doc.vector used as feature

    pure_text section:
        1) same as Subject section (1,2,3)
        2) token.vector used as features

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.170314
total feature number = 7952147

Classification report:
              precision    recall  f1-score   support

           1       0.75      0.78      0.77       209
           2       0.69      0.74      0.71       253
           3       0.69      0.80      0.74       250
           4       0.71      0.66      0.69       238
           5       0.88      0.80      0.84       233
           6       0.82      0.78      0.80       237
           7       0.75      0.74      0.74       245
           8       0.88      0.85      0.86       241
           9       0.85      0.89      0.87       244
          10       0.92      0.89      0.91       247
          11       0.97      0.92      0.94       246
          12       0.90      0.84      0.87       240
          13       0.78      0.78      0.78       223
          14       0.87      0.86      0.87       248
          15       0.87      0.90      0.88       258
          16       0.79      0.86      0.83       250
          17       0.87      0.84      0.86       224
          18       0.93      0.88      0.90       255
          19       0.80      0.84      0.82       200
          20       0.66      0.68      0.67       166

    accuracy                           0.82      4707
   macro avg       0.82      0.82      0.82      4707
weighted avg       0.82      0.82      0.82      4707

Accuracy score:
0.8196303377947738

6th word vectors baseline:

features:
    1) input data split into 'From', 'Subject' and 'pure_text' sections
    From section:
        1) All non-alphanumeric characters replaced with whitespace
    Subject section:
        1) Only tokens.is_alpha kept
        2) token.is_stop dropped
        3) tokens converted to token.lower
        4) token.vector used as feature

    pure_text section:
        1) same as Subject section (1,2,3)
        2) token.lower used as features

Classification report:
              precision    recall  f1-score   support

           1       0.92      0.88      0.90       209
           2       0.81      0.75      0.78       253
           3       0.78      0.80      0.79       250
           4       0.74      0.72      0.73       238
           5       0.79      0.88      0.83       233
           6       0.78      0.82      0.80       237
           7       0.83      0.82      0.83       245
           8       0.91      0.92      0.91       241
           9       0.87      0.92      0.90       244
          10       0.95      0.88      0.92       247
          11       0.95      0.95      0.95       246
          12       0.95      0.95      0.95       240
          13       0.83      0.81      0.82       223
          14       0.90      0.88      0.89       248
          15       0.95      0.93      0.94       258
          16       0.89      0.92      0.90       250
          17       0.94      0.88      0.91       224
          18       0.96      0.96      0.96       255
          19       0.92      0.90      0.91       200
          20       0.81      0.89      0.85       166

    accuracy                           0.87      4707
   macro avg       0.87      0.87      0.87      4707
weighted avg       0.87      0.87      0.87      4707

Accuracy score:
0.8731676226896112

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.228312
total feature number = 20297147

1st word vectors v2 baseline:

features:
1) 'From' section dropped
2) Word vectors normalised to [-1, 1]

Classification report:
              precision    recall  f1-score   support

           1       0.82      0.82      0.82       209
           2       0.78      0.77      0.78       253
           3       0.76      0.84      0.80       250
           4       0.76      0.75      0.75       238
           5       0.83      0.86      0.84       233
           6       0.82      0.87      0.85       237
           7       0.82      0.78      0.80       245
           8       0.90      0.87      0.89       241
           9       0.91      0.91      0.91       244
          10       0.95      0.95      0.95       247
          11       0.96      0.96      0.96       246
          12       0.95      0.86      0.91       240
          13       0.84      0.82      0.83       223
          14       0.89      0.88      0.89       248
          15       0.89      0.94      0.91       258
          16       0.82      0.90      0.86       250
          17       0.91      0.90      0.90       224
          18       0.94      0.89      0.92       255
          19       0.87      0.86      0.86       200
          20       0.82      0.78      0.80       166

    accuracy                           0.86      4707
   macro avg       0.86      0.86      0.86      4707
weighted avg       0.86      0.86      0.86      4707

Accuracy score:
0.8625451455279372

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.233978
total feature number = 458290728

2nd word vectors v2 baseline:

features:
1) Subj doc vectors taken and normalised to [0, 1]
1) pure_text word vectors normalised to [0, 1]

Classification report:
              precision    recall  f1-score   support

           1       0.86      0.84      0.85       209
           2       0.86      0.82      0.84       253
           3       0.75      0.84      0.80       250
           4       0.82      0.76      0.79       238
           5       0.88      0.88      0.88       233
           6       0.89      0.88      0.89       237
           7       0.85      0.84      0.85       245
           8       0.92      0.92      0.92       241
           9       0.98      0.93      0.96       244
          10       0.97      0.98      0.97       247
          11       0.98      0.98      0.98       246
          12       0.96      0.91      0.94       240
          13       0.86      0.87      0.87       223
          14       0.92      0.94      0.93       248
          15       0.93      0.95      0.94       258
          16       0.88      0.93      0.90       250
          17       0.94      0.92      0.93       224
          18       0.96      0.94      0.95       255
          19       0.85      0.86      0.86       200
          20       0.75      0.81      0.78       166

    accuracy                           0.89      4707
   macro avg       0.89      0.89      0.89      4707
weighted avg       0.89      0.89      0.89      4707

Accuracy score:
0.8922880815806246

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.193966
total feature number = 446198753


3rd word vectors v2 baseline:
Features:
1) Dropped 'From' section

Classification report:
              precision    recall  f1-score   support

           1       0.86      0.84      0.85       209
           2       0.86      0.82      0.84       253
           3       0.75      0.84      0.80       250
           4       0.82      0.76      0.79       238
           5       0.88      0.88      0.88       233
           6       0.90      0.88      0.89       237
           7       0.85      0.84      0.85       245
           8       0.92      0.92      0.92       241
           9       0.98      0.93      0.96       244
          10       0.97      0.98      0.97       247
          11       0.98      0.98      0.98       246
          12       0.96      0.91      0.94       240
          13       0.86      0.87      0.86       223
          14       0.92      0.94      0.93       248
          15       0.93      0.95      0.94       258
          16       0.88      0.93      0.90       250
          17       0.94      0.92      0.93       224
          18       0.96      0.94      0.95       255
          19       0.85      0.86      0.86       200
          20       0.75      0.81      0.78       166

    accuracy                           0.89      4707
   macro avg       0.89      0.89      0.89      4707
weighted avg       0.89      0.89      0.89      4707

Accuracy score:
0.8922880815806246

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.194462
total feature number = 446077728


testing out sentence vectors:

tldr: CMI

Classification report:
              precision    recall  f1-score   support

           1       0.74      0.83      0.78       209
           2       0.30      0.62      0.41       253
           3       0.59      0.63      0.61       250
           4       0.98      0.42      0.59       238
           5       0.68      0.60      0.64       233
           6       0.94      0.40      0.56       237
           7       0.20      0.60      0.30       245
           8       0.95      0.71      0.81       241
           9       0.91      0.80      0.85       244
          10       0.99      0.66      0.79       247
          11       0.98      0.70      0.82       246
          12       0.99      0.77      0.86       240
          13       0.90      0.67      0.77       223
          14       0.79      0.75      0.77       248
          15       0.65      0.81      0.72       258
          16       0.89      0.78      0.83       250
          17       0.94      0.78      0.85       224
          18       0.99      0.67      0.80       255
          19       0.90      0.78      0.83       200
          20       0.86      0.77      0.81       166

    accuracy                           0.69      4707
   macro avg       0.81      0.69      0.72      4707
weighted avg       0.80      0.69      0.72      4707

Accuracy score:
0.685362226471213

finished run
number of examples = 18828
weighted example sum = 18828.000000
weighted label sum = 0.000000
average loss = 0.502160
total feature number = 129365328

4th word vectors v2 baseline:
Features:
1) Combined subject and pure_text as one section

Classification report:
              precision    recall  f1-score   support

           1       0.85      0.86      0.85       209
           2       0.84      0.83      0.83       253
           3       0.80      0.85      0.83       250
           4       0.83      0.75      0.79       238
           5       0.90      0.85      0.88       233
           6       0.90      0.91      0.90       237
           7       0.83      0.90      0.86       245
           8       0.92      0.93      0.92       241
           9       0.96      0.94      0.95       244
          10       0.98      0.98      0.98       247
          11       0.99      0.98      0.98       246
          12       0.97      0.91      0.94       240
          13       0.86      0.88      0.87       223
          14       0.93      0.94      0.94       248
          15       0.95      0.95      0.95       258
          16       0.89      0.92      0.91       250
          17       0.95      0.93      0.94       224
          18       0.96      0.93      0.95       255
          19       0.88      0.88      0.88       200
          20       0.73      0.83      0.78       166

    accuracy                           0.90      4707
   macro avg       0.90      0.90      0.90      4707
weighted avg       0.90      0.90      0.90      4707

Accuracy score:
0.8988740174208626

1st word vectors v3 baseline:

Features:
1) Used text_data as features
2) Replaced spacy.vectors with bpemb english model

Classification report:
              precision    recall  f1-score   support

           1       0.83      0.86      0.84       209
           2       0.87      0.84      0.86       253
           3       0.80      0.88      0.84       250
           4       0.83      0.77      0.80       238
           5       0.92      0.88      0.90       233
           6       0.89      0.91      0.90       237
           7       0.87      0.90      0.89       245
           8       0.94      0.92      0.93       241
           9       0.97      0.95      0.96       244
          10       0.98      0.98      0.98       247
          11       0.98      0.96      0.97       246
          12       0.97      0.90      0.94       240
          13       0.85      0.88      0.86       223
          14       0.95      0.94      0.95       248
          15       0.94      0.95      0.94       258
          16       0.87      0.94      0.90       250
          17       0.94      0.92      0.93       224
          18       0.96      0.93      0.95       255
          19       0.91      0.86      0.88       200
          20       0.72      0.81      0.76       166

    accuracy                           0.90      4707
   macro avg       0.90      0.90      0.90      4707
weighted avg       0.90      0.90      0.90      4707

Accuracy score:
0.9016358614828978

